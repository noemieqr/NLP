{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas, csv\n",
    "import re\n",
    "import collections\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "#from nltk.align.bleu import BLEU\n",
    "\n",
    "def readData(filename):\n",
    "\t\n",
    "\tdf = pandas.read_csv(filename, \"IS230\", names = [\"mr\"])\n",
    "\tdf_new = pandas.DataFrame(columns=[\"mr\", \"ref\"])\n",
    "\t#df_new = pandas.DataFrame(columns=[\"mr\", \"ref\", \"generated_utterance\"])\n",
    "\n",
    "\tmr = []\n",
    "\tref = []\n",
    "\t#generated_utterance = []\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tif index == 0: continue\n",
    "\t\t\n",
    "\t\tnew_row = row[\"mr\"].split(\"\\\",\")\n",
    "\t\tif(len(new_row) == 2):\n",
    "\t\t#if(len(new_row) == 3):\n",
    "\t\t\tmr.append(str(new_row[0]))\n",
    "\t\t\tref.append(str(new_row[1]))\n",
    "\t\t\t#generated_utterance.append(str(new_row[2]))\n",
    "\tdf_new['mr'] = mr\n",
    "\tdf_new['ref'] = ref\n",
    "\t#df_new['generated_utterance'] = generated_utterance\n",
    "\treturn(df_new)\n",
    "\t\n",
    "\n",
    "def generateDict(df):\n",
    "\tmr_dict = collections.defaultdict(dict)\n",
    "\n",
    "\tfor index, row in df.iterrows():\n",
    "\n",
    "\t\tmr = row['mr']\n",
    "\t\tutterance = row['ref']\n",
    "\n",
    "\t\tslot_str, attrib_value_dict = getSlotValuePairs(mr)\n",
    "\t\tmr_dict.update({slot_str:(utterance, attrib_value_dict)})\n",
    "\n",
    "\treturn mr_dict\n",
    "\n",
    "\n",
    "def getSlotValuePairs(mr):\n",
    "\t#test_mr_dict = collections.defaultdict(dict)\n",
    "\n",
    "\tmr = mr.replace(\"\\\"\", \"\")\n",
    "\tslots = mr.split(\",\")\n",
    "\n",
    "\tslot_values= [re.search(r'\\[(.*)\\]', slot).group(1) for slot in slots]\n",
    "\tslot_attrib = [re.search(r'(.*)\\[.*\\]', slot).group(1) for slot in slots]\n",
    "\n",
    "\t#print(slot_values)\n",
    "\t#print(slot_attrib)\n",
    "\n",
    "\tattrib_value_dict = {}\n",
    "\tslot_str = \"\"\n",
    "\t\t\n",
    "\tfor i in range(0, len(slots)):\n",
    "\t\tattrib_value_dict.update({slot_attrib[i]:slot_values[i]})\n",
    "\t\tslot_str = slot_str+str(slot_attrib[i])+\",\"\n",
    "\tslot_str = slot_str.strip(\",\")\n",
    "\t#test_mr_dict.update({slot_str:attrib_value_dict})\n",
    "\treturn (slot_str, attrib_value_dict)\n",
    "\n",
    "\n",
    "def retrieveResponse(mr_dict, test_slot_attrib_value):\n",
    "\n",
    "\ttest_slot_str, test_attrib_value_dict = test_slot_attrib_value\n",
    "\n",
    "\ttest_slot_str = test_slot_str.split(\",\")\n",
    "\ttest_slot_set = set(test_slot_str)\n",
    "\n",
    "\tfor key in mr_dict:\n",
    "\t\tslot_str = key.split(\",\")\n",
    "\t\tslot_set = set(slot_str)\n",
    "\t\tif(test_slot_set == slot_set):\n",
    "\t\t\tutterance, train_dict = mr_dict[key]\n",
    "\t\t\treturn(modifyUtterance(utterance, train_dict, test_attrib_value_dict))\n",
    "\t\tcontinue\n",
    "\treturn None\n",
    "\t\n",
    "\n",
    "def modifyUtterance(utterance, train_dict, test_dict):\n",
    "\t\n",
    "\tfor key in train_dict:\n",
    "\t\tif(train_dict[key] in utterance):\n",
    "\t\t\t#print(\"word in train: \"+str(train_dict[key]))\n",
    "\t\t\t#print(\"utterance: \"+str(utterance))\n",
    "\t\t\tnew_value = test_dict[key]\n",
    "\t\t\tutterance = utterance.replace(train_dict[key], new_value)\n",
    "\t\t\t#print(\"updated utterance: \"+str(utterance))\n",
    "\t\t\n",
    "\treturn utterance\n",
    "\n",
    "\n",
    "def calculateSlotMatchingRate(reference_utterances, predicted_utterances):\n",
    "\t#The slot matching rate is the percentage of delexicalised tokens (e.g. [s.food] and [v.area] appear in the candidate also appear in the reference.\n",
    "\t#cosine distance between word2vec embeddings\n",
    "\t#generated_dict = find_slot_value_tokens(predicted_utterances)\n",
    "\tpass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\t\n",
    "\ttrain_data = \"data_analytics/data/trainset.csv\"\n",
    "\tdev_data = \"data_analytics/data/devset.csv\"\n",
    "\tdf = readData(train_data)\n",
    "\tmr_dict = generateDict(df)\n",
    "\t\n",
    "\ttest_mr = \"name[Adios], food[Spanish], customer rating[high], familyFriendly[yes], near[Ranch]\"\n",
    "\ttest_slot_attrib_value = getSlotValuePairs(test_mr)\n",
    "\tprint(retrieveResponse(mr_dict, test_slot_attrib_value))\n",
    "\n",
    "\ttest_df = readData(dev_data)\n",
    "\tgenerated_utterances = []\n",
    "\tfor index, row in test_df.iterrows():\n",
    "\t\tmr = row['mr']\n",
    "\t\tutterance = row['ref']\n",
    "\n",
    "\t\ttest_slot_attrib_value = getSlotValuePairs(mr)\n",
    "\t\tgenerated_utterances.append(retrieveResponse(mr_dict, test_slot_attrib_value))\n",
    "\n",
    "\twith open('baseline_predictions.txt', mode='w') as f:\n",
    "\t\tfor line in generated_utterances:\n",
    "\t\t\tf.write(str(line).replace('\"', \"\")+'\\n')\n",
    "\n",
    "\n",
    "\t#test_df[\"generated_utterance\"] = generated_utterances\n",
    "\t#test_df.to_csv(\"baseline_\"+dev_data.split(\".\")[0]+\"-new.csv\")\n",
    "\t\n",
    "\n",
    "\t#generated = nltk.word_tokenize(\"The Blue Spice is a non-family-friendly coffee shop in the city centre near Avalon with a 5 out of 5 customer rating and has a cheap price range.\")\n",
    "\t#BLEU: 0.2767774344774222\n",
    "\n",
    "\t#generated = nltk.word_tokenize(\"It is a nice shop.\")\n",
    "\t#ref = [nltk.word_tokenize(\"Blue Spice as a coffee shop  near Avalon in the city centre may not be a smart choice for family and is less than 20 with a 5 out of 5 rating.\")]\n",
    "\t#print(sentence_bleu(ref, generated))\n",
    "\n",
    "\t'''\n",
    "\tresult_df = readData(\"devset-new.csv\")\n",
    "\ttotal_bleu = 0.0\n",
    "\tfor index, row in result_df.iterrows():\n",
    "\t\tref = [nltk.word_tokenize(row['ref'])]\n",
    "\t\tgenerated = nltk.word_tokenize(row['generated_utterance'])\n",
    "\t\ttotal_bleu = total_bleu + sentence_bleu(ref, generated)\n",
    "\tavg_bleu = total_bleu/(index+1)\n",
    "\tprint(\"Average BLEU: \"+str(avg_bleu))\n",
    "\t'''\n",
    "\n",
    "\t#Average BLEU: 0.234019592971\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
