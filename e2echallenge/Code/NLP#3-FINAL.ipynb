{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../e2e-dataset/trainset.csv', encoding='utf8')\n",
    "df_test = pd.read_csv('../e2e-dataset/devset.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mr</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name[The Vaults], eatType[pub], priceRange[mor...</td>\n",
       "      <td>The Vaults pub near Café Adriatic has a 5 star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name[The Cambridge Blue], eatType[pub], food[E...</td>\n",
       "      <td>Close to Café Brazil, The Cambridge Blue pub s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name[The Eagle], eatType[coffee shop], food[Ja...</td>\n",
       "      <td>The Eagle is a low rated coffee shop near Burg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>name[The Mill], eatType[coffee shop], food[Fre...</td>\n",
       "      <td>Located near The Sorrento is a French Theme ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name[Loch Fyne], food[French], customer rating...</td>\n",
       "      <td>For luxurious French food, the Loch Fyne is lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  mr  \\\n",
       "0  name[The Vaults], eatType[pub], priceRange[mor...   \n",
       "1  name[The Cambridge Blue], eatType[pub], food[E...   \n",
       "2  name[The Eagle], eatType[coffee shop], food[Ja...   \n",
       "3  name[The Mill], eatType[coffee shop], food[Fre...   \n",
       "4  name[Loch Fyne], food[French], customer rating...   \n",
       "\n",
       "                                                 ref  \n",
       "0  The Vaults pub near Café Adriatic has a 5 star...  \n",
       "1  Close to Café Brazil, The Cambridge Blue pub s...  \n",
       "2  The Eagle is a low rated coffee shop near Burg...  \n",
       "3  Located near The Sorrento is a French Theme ea...  \n",
       "4  For luxurious French food, the Loch Fyne is lo...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'name[The Vaults], eatType[pub], priceRange[more than \\xa330], customer rating[5 out of 5], near[Caf\\xe9 Adriatic]'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0].mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'The Vaults pub near Caf\\xe9 Adriatic has a 5 star rating.  Prices start at \\xa330.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[0].ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- name[The Eagle]\n",
    "- eatType[coffee shop]\n",
    "- food[French]\n",
    "- priceRange[moderate]\n",
    "- customerRating[3/5]\n",
    "- area[riverside]\n",
    "- kidsFriendly[yes]\n",
    "- near[Burger King]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "types = ['name', 'eatType', 'food', 'priceRange', 'customer rating', 'area', 'familyFriendly', 'near']\n",
    "for s in df_train.mr:\n",
    "    comps = s.split(',')\n",
    "    for c in comps:\n",
    "        for t in types:\n",
    "            c = c.strip()\n",
    "            if c.startswith(t):\n",
    "                if t not in d:\n",
    "                    d[t] = set()\n",
    "                \n",
    "                val = c[len(t)+1:].replace(']', '')\n",
    "                d[t].add(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a mapping that converts the mr type to an Id for the feature vector\n",
    "type2id = {'name':0, 'near':1}\n",
    "i = 2\n",
    "for k, v in d.items():\n",
    "    if k not in ['name', 'near']:\n",
    "        for a in v:\n",
    "            type2id[(k,a)] = i\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A list of attributes that can be 'not specified'\n",
    "not_specified = ['eatType', 'food', 'priceRange', 'customer rating', 'area', 'familyFriendly', 'near']\n",
    "for a in not_specified:\n",
    "    type2id[(a, 'not specified')] = len(type2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = ['name', 'eatType', 'food', 'priceRange', 'customer rating', 'area', 'familyFriendly', 'near']\n",
    "def process_mr(s):\n",
    "    mr = []\n",
    "    \n",
    "    comps = s.split(',')\n",
    "    for c in comps:\n",
    "        for t in types:\n",
    "            c = c.strip()\n",
    "            if c.startswith(t):\n",
    "                val = c[len(t)+1:].replace(']', '')\n",
    "                mr.append((t, val))\n",
    "    return mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_mrs_train = [process_mr(s) for s in df_train.mr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_feature_vector(mrs):\n",
    "    vec = np.zeros(len(type2id))\n",
    "    \n",
    "    specified = set()\n",
    "    for k,v in mrs:\n",
    "        specified.add(k)\n",
    "        if k in ['name', 'near']:\n",
    "            vec[type2id[k]] = 1\n",
    "        else:\n",
    "            vec[type2id[(k,v)]] = 1\n",
    "    \n",
    "    # Add the non specified keys as well\n",
    "    for not_specified in set(types) - specified:\n",
    "        vec[type2id[(k, 'not specified')]] = 1\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_feature_vectors = np.array([to_feature_vector(x) for x in processed_mrs_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42061, 35)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace the name and near values from the meaning representation with a specific token\n",
    "sents = df_train.ref.values\n",
    "\n",
    "proc_sents = []\n",
    "for i_s in range(len(sents)):\n",
    "    s = sents[i_s]\n",
    "    mr = processed_mrs_train[i_s]\n",
    "    for k,v in mr:\n",
    "        if k == 'name':\n",
    "            s = s.replace(v, ' <name> ')\n",
    "        elif k == 'near':\n",
    "            s = s.replace(v, ' <near> ')\n",
    "        elif k == 'food':\n",
    "            s = s.replace(v, ' <food> ')\n",
    "        elif k == 'eatType':\n",
    "            s = s.replace(v, ' <eatType> ')\n",
    "    proc_sents.append(s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = {'<name>', '<near>', '<food>', '<eattype>', '<bos>', '<eos>'}\n",
    "tokens = {'<name>', '<near>', '<food>', '<eattype>', '<bos>', '<eos>'}\n",
    "for s in proc_sents:\n",
    "    \n",
    "    # for every c=character in s=sentence\n",
    "    for c in s:\n",
    "        vocab.update(c)\n",
    "        \n",
    "vocab = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char2id = {vocab[i]:i for i in range(len(vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u' <name>   <eattype>  near  <near>  has a 5 star rating.  prices start at \\xa330.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bitches = []\n",
    "for s in proc_sents:\n",
    "    sent_ids = [char2id['<bos>']]\n",
    "    \n",
    "    comps = s.split(' ')\n",
    "    for i in range(len(comps)):\n",
    "        word = comps[i]\n",
    "        \n",
    "        if word == '<name>':\n",
    "            sent_ids.append(char2id['<name>'])\n",
    "        elif word == '<near>':\n",
    "            sent_ids.append(char2id['<near>'])\n",
    "        elif word == '<food>':\n",
    "            sent_ids.append(char2id['<food>'])\n",
    "        elif word == 'eatType':\n",
    "            sent_ids.append(char2id['<eattype>'])\n",
    "        else:\n",
    "            # For c=character in word\n",
    "            for c in word:\n",
    "                sent_ids.append(char2id[c])\n",
    "                \n",
    "            # Don't add a whitespace after the last word\n",
    "            if i < len(comps) - 1:\n",
    "                sent_ids.append(char2id[' '])\n",
    "            \n",
    "    sent_ids.append(char2id['<eos>'])\n",
    "    bitches.append(sent_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_len = 150\n",
    "X_data = [] #np.array((len(bitches), max_seq_len, len(vocab)))\n",
    "for i in range(len(bitches)):\n",
    "    b = bitches[i]\n",
    "    \n",
    "    S = np.zeros((max_seq_len, len(vocab)))\n",
    "    for j in range(len(b)):\n",
    "        if j >= len(vocab):\n",
    "            break\n",
    "        \n",
    "        vec = np.zeros(len(vocab))\n",
    "        vec[b[j]] = 1\n",
    "        S[j] = vec\n",
    "    X_data.append(S)\n",
    "    \n",
    "X_data = np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42061, 149, 59)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[:,1:,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input_data = X_feature_vectors.reshape((len(proc_sents), 1, len(type2id)))\n",
    "decoder_input_data = X_data\n",
    "\n",
    "# Shift the target data and pad it \n",
    "npad = ((0, 0), (0, 1), (0, 0))\n",
    "decoder_target_data = np.pad(X_data[:,1:,:], pad_width=npad, mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 5  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = len(proc_sents)  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(type2id)\n",
    "num_decoder_tokens = len(vocab)\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "_, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33648 samples, validate on 8413 samples\n",
      "Epoch 1/5\n",
      "33648/33648 [==============================] - 571s 17ms/step - loss: 0.6743 - val_loss: 0.3301\n",
      "Epoch 2/5\n",
      "33648/33648 [==============================] - 591s 18ms/step - loss: 0.2709 - val_loss: 0.2330\n",
      "Epoch 3/5\n",
      "33648/33648 [==============================] - 607s 18ms/step - loss: 0.2156 - val_loss: 0.2028\n",
      "Epoch 4/5\n",
      "33648/33648 [==============================] - 611s 18ms/step - loss: 0.1940 - val_loss: 0.1876\n",
      "Epoch 5/5\n",
      "33648/33648 [==============================] - 610s 18ms/step - loss: 0.1807 - val_loss: 0.1749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10a501750>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], \n",
    "          decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    model_json = model.to_json()\n",
    "    with open(name + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_weights` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-ed65f89b415c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-9469cd287a36>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, name)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Rafaelle/Desktop/Projet/User/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m   2598\u001b[0m         \"\"\"\n\u001b[1;32m   2599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2600\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2601\u001b[0m         \u001b[0;31m# If file exists and should not be overwritten:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_weights` requires h5py."
     ]
    }
   ],
   "source": [
    "save_model(encoder_model, 'encoder')\n",
    "save_model(decoder_model, 'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('char2id.json', 'w') as outfile:\n",
    "    json.dump(char2id, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(type2id, open('type2id.json', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id2char = {v:k for k,v in char2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_decoder_seq_length = 150\n",
    "def decode_sequence(input_seq):\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, char2id['<bos>']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = id2char[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '<eos>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        # At most 2 sentences in the utterance\n",
    "        if decoded_sentence.count('.') >= 2:\n",
    "            decoded_sentence = \".\".join(decoded_sentence.split(\".\", 2)[:2])+'.'\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_feature_vectors[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('name', u'Blue Spice')\n",
      "('food', u'French')\n",
      "('priceRange', u'more than \\xa330')\n",
      "('area', u'riverside')\n"
     ]
    }
   ],
   "source": [
    "for x in processed_mrs_train[24]:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u' The Vaults is a  pub  near  Caf\\xe9 Adriatic that serves   food. it is located in the riverside area.',\n",
       " u' The Cambridge Blue is a  pub  that serves  English food in the city centre near  Caf\\xe9 Brazil. it has a high customer rating and is not family-friendly.',\n",
       " u' The Eagle is a  coffee shop  that serves  Japanese food in the city centre near  Burger King. it is kid friendly.',\n",
       " u' The Mill is a  coffee shop  near  The Sorrento that serves  French food. it is not kid friendly.',\n",
       " u' Loch Fyne is a  French restaurant located near  The Rice Boat.',\n",
       " u' Bibimbap House is a moderate priced restaurant located near  Clare Hall. it is not kid friendly.',\n",
       " u' The Rice Boat is a  French restaurant with a high customer rating and is not family-friendly.',\n",
       " u' The Wrestlers is a  coffee shop  that serves  Japanese food in the city centre near  Raja Indian Cuisine. it has a high customer rating and is not family-friendly.',\n",
       " u' Aromi is a  coffee shop  that serves  French food in the city centre. it is not family-friendly.',\n",
       " u' The Phoenix is a moderately priced  Fast food restaurant with a customer rating of 3 out of 5.',\n",
       " u' Browns Cambridge is a family friendly  Fast food restaurant near  The Sorrento.',\n",
       " u' Loch Fyne is a  restaurant  that serves  English food. it is kid friendly.',\n",
       " u' Taste of Cambridge is a  restaurant  with a moderate price range and is not kids friendly.',\n",
       " u' Cocum is a cheap  coffee shop  that serves  Italian food. it is located in the city centre.',\n",
       " u' The Dumpling Tree is a  restaurant  that serves  Italian food. it is located in the city centre.',\n",
       " u' The Punter is a  Indian restaurant with a high customer rating and is not family-friendly.',\n",
       " u' The Golden Curry is a family friendly restaurant located near  Caf\\xe9 Rouge. it is not family-friendly.',\n",
       " u' The Phoenix is a high priced  English restaurant with a high customer rating and is not family-friendly.',\n",
       " u' Alimentum is a family friendly  Fast food restaurant near  Yippee Noodle Bar. it has a high customer rating and is not family-friendly.',\n",
       " u' The Eagle is a  Chinese restaurant with a moderate price range and is not kids friendly.',\n",
       " u' The Punter is a family friendly   restaurant near  The Portland Arms.',\n",
       " u' The Mill is a  coffee shop  near  The Sorrento that serves  Italian food. it is located in the city centre.',\n",
       " u' Midsummer House is a moderate priced  Italian restaurant near  All Bar One in the riverside area. it is not kid friendly.',\n",
       " u' The Rice Boat is a kid friendly  English restaurant near  Express by Holiday Inn in the riverside area. it is not kid friendly.',\n",
       " u' Blue Spice is a  French restaurant with a high customer rating and is not family-friendly.',\n",
       " u' Strada is a  pub  that serves  Italian food in the city centre near  Yippee Noodle Bar. it has a high customer rating and is not family-friendly.',\n",
       " u' Alimentum is a  Chinese restaurant located near  Yippee Noodle Bar. it has a high customer rating and is not family-friendly.',\n",
       " u' The Cambridge Blue is a  pub  that serves  Chinese food in the moderate price range and is not kid friendly and has a moderate price range and is not kid fri',\n",
       " u' The Waterman is a  pub  that serves  Fast food food. it is located in the riverside area.',\n",
       " u' Bibimbap House is a  English restaurant located near  Clare Hall.',\n",
       " u' Zizzi is a  pub  that serves  French food. it is kid friendly.',\n",
       " u' Alimentum is a  Italian restaurant with a high customer rating and is not family-friendly.',\n",
       " u' The Wrestlers is a  coffee shop  that serves  Italian food in the city centre near  Raja Indian Cuisine. it is kid friendly.',\n",
       " u' The Golden Curry is a  English restaurant near  The Bakers with a high customer rating and is not family-friendly.',\n",
       " u' Green Man is a  French restaurant located near  All Bar One. it is not family-friendly.',\n",
       " u' The Waterman is a   restaurant with a high customer rating and is not family-friendly.',\n",
       " u' Zizzi is a  restaurant  with a high customer rating and is not family-friendly.',\n",
       " u' The Golden Curry is a  Indian restaurant near  Caf\\xe9 Rouge with a high customer rating and is not family-friendly.',\n",
       " u' The Dumpling Tree is a  restaurant  that serves  Japanese food. it is located in the city centre.',\n",
       " u' The Punter is a  coffee shop  that serves  Japanese food in the city centre near  Caf\\xe9 Sicilia. it is child friendly and has a customer rating of 3 out of 5.',\n",
       " u' Clowns is a  coffee shop  that serves  Italian food in the city centre near  Clare Hall. it has a high customer rating and is not family-friendly.',\n",
       " u' The Dumpling Tree is a  pub  that serves  Japanese food in the city centre near  The Portland Arms. it has a high customer rating and is not family-friendly.',\n",
       " u' Blue Spice is a  coffee shop  near  Avalon that serves   food. it is located in the riverside area.',\n",
       " u' Giraffe is a family friendly  pub  that serves  Fast food food. it is located in the riverside area.',\n",
       " u' Browns Cambridge is a family friendly restaurant located near  The Sorrento. it is not family-friendly.',\n",
       " u' Cocum is a  coffee shop  that serves  Italian food. it is kid friendly and has a customer rating of 3 out of 5.',\n",
       " u' The Punter is a cheap  coffee shop  that serves  Italian food in the city centre near  Caf\\xe9 Sicilia. it is child friendly.',\n",
       " u' The Olive Grove is a  pub  that serves  Indian food in the moderate price range. it is located in the city centre.',\n",
       " u' Giraffe is a  restaurant  near  The Six Bells in the city centre. it is not family-friendly.',\n",
       " u' Cocum is a kid friendly  restaurant  with a moderate price range. it is located in the riverside area.']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just to be sure it's working: \n",
    "l=50\n",
    "\n",
    "decoded = []\n",
    "\n",
    "decoded = map(lambda i: decode_sequence(X_feature_vectors[i].reshape((1,1,len(type2id)))), range(l)) \n",
    "\n",
    "# Replace slot placeholders by their values\n",
    "decoded = map(lambda i: decoded[i].replace('<name>', dict(processed_mrs_train[i])['name']), range(l))\n",
    "decoded = map(lambda i: decoded[i].replace('<near>', dict(processed_mrs_train[i])['near']) if 'near' in \n",
    "              dict(processed_mrs_train[i]) else decoded[i], range(l))\n",
    "decoded = map(lambda i: decoded[i].replace('<food>', dict(processed_mrs_train[i])['food']) if 'food' in \n",
    "              dict(processed_mrs_train[i]) else decoded[i].replace('<food>',''), range(l))\n",
    "decoded = map(lambda i: decoded[i].replace('<eattype>', dict(processed_mrs_train[i])['eatType']) if 'eatType' in\n",
    "              dict(processed_mrs_train[i]) else decoded[i], range(l))\n",
    "decoded = map(lambda i: decoded[i].replace('<eos>','') if '<eos>' in decoded[i] else decoded[i], range(l))\n",
    "\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_processing(self, X, type2id, processed_mrs):\n",
    "    \n",
    "    # Decode every sentence (which is for now a binary vector)\n",
    "    results = []\n",
    "    results = map(lambda i: self.decode_sequence(X[i].reshape((1,1,len(type2id)))), range(len(X))) \n",
    "\n",
    "    # Replace slot placeholders by their values\n",
    "    # Name\n",
    "    results = map(lambda i: results[i].replace('<name>', dict(processed_mrs[i])['name']), range(len(X)))\n",
    "    \n",
    "    # Near\n",
    "    results = map(lambda i: results[i].replace('<near>', dict(processed_mrs[i])['near']) if 'near' in \n",
    "                  dict(processed_mrs[i]) else results[i], range(len(X)))\n",
    "    \n",
    "    # Food\n",
    "    results = map(lambda i: results[i].replace('<food>', dict(processed_mrs[i])['food']) if 'food' in \n",
    "                  dict(processed_mrs[i]) else results[i].replace('<food>',''), range(len(X)))\n",
    "    \n",
    "    # Eat Type\n",
    "    results = map(lambda i: results[i].replace('<eattype>', dict(processed_mrs[i])['eatType']) if 'eatType' in\n",
    "                  dict(processed_mrs[i]) else results[i], range(len(X)))\n",
    "    \n",
    "    # End of sentence\n",
    "    results = map(lambda i: results[i].replace('<eos>','') if '<eos>' in results[i] else results[i], range(len(X)))\n",
    "    \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
