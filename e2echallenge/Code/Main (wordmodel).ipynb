{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout \n",
    "from keras.layers import LSTM, RepeatVector, Dense, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas as pd\n",
    "from string import printable\n",
    "\n",
    "def pretty_format(sample):\n",
    "\tcharIds = np.zeros(sample.shape[0])\n",
    "\n",
    "\tfor (idx, elem) in enumerate(sample):\n",
    "\t\tcharIds[idx] =np.nonzero(elem)[0].squeeze()\n",
    "\treturn  ''.join(np.array([ int_to_char[x] for x in charIds])) \n",
    "\n",
    "def get_sequences(dataframe, max_sequen_len, dict_len):\n",
    "\tx_seq=np.zeros( (dataframe.shape[0], max_sequen_len, dict_len), dtype=np.bool)\n",
    "\ty_seq=np.zeros( (dataframe.shape[0], max_sequen_len, dict_len), dtype=np.bool)\n",
    "\t#iterators\n",
    "\ti=0\n",
    "\tfor index, row in dataframe.iterrows():\n",
    "\t\tx_seq[i,0, char_to_int['S']]=1\n",
    "\t\ty_seq[i,0, char_to_int['S']]=1\n",
    "\t\tfor j in range(1, max_seq_length):\n",
    "\t\t\tif j< len(row['mr'])+1:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tx_seq[i,j, char_to_int[row['mr'][j-1] ] ]=1\n",
    "\t\t\t\texcept KeyError:\n",
    "\t\t\t\t\t#pass \n",
    "\t\t\t\t\tx_seq[i,j, char_to_int[ ' ' ] ]=1 #CHANGE THIS!!!\n",
    "\t\t\telse:\n",
    "\t\t\t\tx_seq[i,j, char_to_int['E']]=1 #end of str\n",
    "\n",
    "\t\t\tif j< len(row['ref'])+1:\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\ty_seq[i,j,char_to_int[row['ref'][j-1] ] ]=1\n",
    "\t\t\t\texcept KeyError:\n",
    "\t\t\t\t\ty_seq[i,j,char_to_int[' ']]=1 #CHANGE THIS!!!\n",
    "\t\t\telse:\n",
    "\t\t\t\ty_seq[i,j, char_to_int['E']]=1 #end of str\n",
    "\n",
    "\t\t\t\n",
    "\t\ti+=1\n",
    "\n",
    "\treturn (x_seq,y_seq)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t\n",
    "\n",
    "\tfilename_train='data/devset_3_slot_mr.csv' #set to traiset\n",
    "\t#df_train=pd.read_csv(filename_train, encoding=\"latin-1\") #linux/windows\n",
    "\tdf_train=pd.read_csv(filename_train) #mac\n",
    "\tfilename_test='data/devset_3_slot_mr.csv'\n",
    "\t#df_test=pd.read_csv(filename_test,encoding=\"latin-1\")\n",
    "\tdf_test=pd.read_csv(filename_test)\n",
    "\n",
    "\n",
    "\n",
    "\tdf_train['mr']=df_train['mr'].astype('str').str.lower() #store column\n",
    "\tdf_train['ref']=df_train['ref'].astype('str').str.lower()\n",
    "\n",
    "\tdf_test['mr']=df_test['mr'].astype('str').str.lower() \n",
    "\tdf_test['ref']=df_test['ref'].astype('str').str.lower() \n",
    "\t\n",
    "\n",
    "\n",
    "\n",
    "\t####set parameters#####\n",
    "\tmr_size=100 \t\t\t\t#char_size of each mr\n",
    "\tmax_output_seq_len = 1+max(len(r['ref']) for i,r in df_train.iterrows() )\t\n",
    "\n",
    "\tmax_input_seq_len = 1+max(len(r['mr']) for i,r in df_train.iterrows() )\n",
    "\n",
    "\tdepth_enc = 1               # number of LSTM layers in the encoder\n",
    "\tdepth_dec = 1 \n",
    "\thiddenStateSize = 187\n",
    "\thiddenLayerSize = 187          \n",
    "\t#######################\n",
    "\tst = set(printable.lower()) #vocabulary\n",
    "\tchars= sorted(list(st)) #vocabulary\n",
    "\tchar_to_int= dict((c,i) for i,c in enumerate(chars))\n",
    "\tint_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "\n",
    "\t#add a special starting and ending character to the dictionary with value start_index.\n",
    "\tstart_index=len(char_to_int)\n",
    "\tchar_to_int['S']=start_index \n",
    "\tint_to_char[start_index]='S'\n",
    "\tchar_to_int['E']=start_index+1\n",
    "\tint_to_char[start_index+1]='E'\n",
    "\n",
    "\n",
    "\t#print summary statistics ( str.len() is vectorized in pandas)\n",
    "\tn_chars_train=df_train['mr'].str.len().sum()+ df_train['ref'].str.len().sum()\n",
    "\tn_chars_test=df_test['mr'].str.len().sum()+ df_test['ref'].str.len().sum()\n",
    "\tn_vocab=len(chars)\n",
    "\t#message\n",
    "\tprint (\"Number of characters in train (before cleanup)=\"+str(n_chars_train))\n",
    "\n",
    "\tprint (\"Number of characters in trest (before cleanup)=\"+str(n_chars_test))\n",
    "\tprint (\"Size of vocabulary =\"+str(n_vocab))\n",
    "\n",
    "\n",
    "\n",
    "\t#prepare the dataset of the input to output pairs encoded as integers\n",
    "\tmax_seq_length=max(max_input_seq_len,max_output_seq_len)\n",
    "\tprint (\"MRs will be padded/truncated to size =\"+str(max_seq_length))\n",
    "\n",
    "\tprint(\"Creating Input Sequences...\")\n",
    "\tx_train,y_train=get_sequences(df_train, max_seq_length, len(char_to_int))\n",
    "\tprint(\"Creating Output Sequences...\")\n",
    "\tx_test, y_test=get_sequences(df_test, max_seq_length, len(char_to_int))\n",
    "\n",
    "\n",
    "\t#DEBUG PRINT\n",
    "\ttrain_x=x_train[10,:,:]\n",
    "\tprint(\"Train sample input: \\n\" + pretty_format(train_x) )\n",
    "\ttrain_y=y_train[10,:,:]\n",
    "\tprint(\"Train sample output: \\n\" + pretty_format(train_y) )\n",
    "\n",
    "\ttest_x=x_test[10,:,:]\n",
    "\tprint(\"Test sample input: \\n\" + pretty_format(test_x) )\n",
    "\ttest_y=y_test[10,:,:]\n",
    "\tprint(\"Test sample output: \\n\" + pretty_format(test_y) )\n",
    "\n",
    "\t\n",
    "\n",
    "\t# ---- BUILD THE MODEL ----\n",
    "\tprint('\\nBuilding language generation model...')\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\t# -- ENCODER --\n",
    "\tmodel.add(Bidirectional(LSTM(units=hiddenLayerSize,\n",
    "                                 dropout=0.2,\n",
    "                                 recurrent_dropout=0.2,\n",
    "                                 return_sequences=False),\n",
    "                            input_shape=(max_seq_length, len(char_to_int))))\n",
    "\n",
    "\t# -- DECODER --\n",
    "\tmodel.add(RepeatVector(max_output_seq_len))\n",
    "\tfor d in range(depth_dec):\n",
    "\t\tmodel.add(LSTM(units=hiddenLayerSize,\n",
    "\t\t\tdropout=0.2,\n",
    "\t\t\trecurrent_dropout=0.2,\n",
    "\t\t\treturn_sequences=True))\n",
    "\t\tmodel.add(TimeDistributed(Dense(len(char_to_int),\n",
    "\t\t\tactivation='softmax')))\n",
    "\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001))\n",
    "\tprint (model.summary())\n",
    "\n",
    "\t# Test a simple prediction on a batch for this model.\n",
    "\tprint(\"Sample input Batch size:\"),\n",
    "\tprint(x_train[0:32, :, :].shape)\n",
    "\tprint(\"Sample input Batch labels (y_train):\"),\n",
    "\tprint(y_train[0:32, :, :].shape)\n",
    "\toutputs = model.predict(y_train[0:32, :, :])\n",
    "\tprint(\"Output Sequence size:\"),\n",
    "\tprint(outputs.shape)\n",
    "\n",
    "\t# ---- Define Checkpoint----\n",
    "\tfilepath=\"CharmodelWeights/weights-improvement-{epoch:02d}-{loss:.4f}.hdf\"\n",
    "\tcheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\tcallbacks_list = [checkpoint]\n",
    "\n",
    "\t# ---- TRAIN ----\n",
    "\tprint('\\nTraining...')\n",
    "\tmodel.fit(x_train,\n",
    "\t y_train, \n",
    "\t batch_size = 128, \n",
    "\t epochs = 1,\n",
    "\t callbacks=callbacks_list)\n",
    "\n",
    "\ttotal=''\n",
    "\tprint(\"Predicting on all test data...\")\n",
    "\n",
    "\t\n",
    "\tfor mr_id in range(0,x_test.shape[0]):\n",
    "\n",
    "\t\t# Test a simple prediction on a batch for this model.\n",
    "\t\tinputMr = x_test[mr_id:mr_id+1, :, :]\n",
    "\t\toutputs = model.predict(inputMr)\n",
    "\n",
    "\t\tsample_in=inputMr[0]\n",
    "\t\tmr=pretty_format(sample_in)\n",
    "\t\t\n",
    "\t\tutt= ''.join([int_to_char[x.argmax()] for x in outputs[0, :, :]])\n",
    "\n",
    "\t\ttotal= total+'\\n \\n'+ mr+'\\n'+utt\n",
    "\n",
    "\tprint(\"Saving output to text file...\")\n",
    "\twith open('char_out.txt','w') as f:\n",
    "\t\tf.write(total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
